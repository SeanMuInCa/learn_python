{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMST/QjN5aHucP2eFFUtl4r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeanMuInCa/learn_python/blob/master/test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t37CukQkEPtF",
        "outputId": "b8b4aa51-0d6a-4a7c-be12-d538a105789e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.107 ðŸš€ Python-3.11.12 torch-2.6.0+cu124 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 41.1/107.7 GB disk)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "cM64DPCVEtI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "model = YOLO('yolov8n.pt') # pretrained basic model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib83uARhE54A",
        "outputId": "531db954-9b02-4938-a83a-5d356fc27bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 20.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y libgtk2.0-dev pkg-config"
      ],
      "metadata": {
        "id": "Dpx-Ruj3GqyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# targets\n",
        "model('licensed-image.jpeg', show=False, save=True)\n",
        "model('1.jpg', show=False, save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhPnyLHKE_sY",
        "outputId": "c32a3bec-b2df-49e3-d05e-ac96f456bbdb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/licensed-image.jpeg: 448x640 1 person, 1 tie, 1 tennis racket, 234.1ms\n",
            "Speed: 5.9ms preprocess, 234.1ms inference, 1.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
            "\n",
            "image 1/1 /content/1.jpg: 512x640 3 persons, 1 tv, 288.0ms\n",
            "Speed: 5.5ms preprocess, 288.0ms inference, 1.7ms postprocess per image at shape (1, 3, 512, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ultralytics.engine.results.Results object with attributes:\n",
              " \n",
              " boxes: ultralytics.engine.results.Boxes object\n",
              " keypoints: None\n",
              " masks: None\n",
              " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
              " obb: None\n",
              " orig_img: array([[[156, 182, 198],\n",
              "         [156, 182, 198],\n",
              "         [156, 182, 198],\n",
              "         ...,\n",
              "         [ 86, 113, 133],\n",
              "         [ 86, 113, 133],\n",
              "         [ 86, 113, 133]],\n",
              " \n",
              "        [[156, 182, 198],\n",
              "         [156, 182, 198],\n",
              "         [156, 182, 198],\n",
              "         ...,\n",
              "         [ 84, 111, 131],\n",
              "         [ 84, 111, 131],\n",
              "         [ 84, 111, 131]],\n",
              " \n",
              "        [[156, 182, 198],\n",
              "         [156, 182, 198],\n",
              "         [156, 182, 198],\n",
              "         ...,\n",
              "         [ 79, 109, 128],\n",
              "         [ 79, 109, 128],\n",
              "         [ 79, 109, 128]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[135, 165, 182],\n",
              "         [136, 166, 183],\n",
              "         [136, 166, 183],\n",
              "         ...,\n",
              "         [123, 183, 225],\n",
              "         [123, 183, 225],\n",
              "         [123, 183, 225]],\n",
              " \n",
              "        [[130, 163, 179],\n",
              "         [132, 165, 181],\n",
              "         [135, 165, 182],\n",
              "         ...,\n",
              "         [125, 183, 225],\n",
              "         [125, 183, 225],\n",
              "         [125, 183, 225]],\n",
              " \n",
              "        [[128, 161, 177],\n",
              "         [130, 163, 179],\n",
              "         [134, 164, 181],\n",
              "         ...,\n",
              "         [125, 183, 225],\n",
              "         [125, 183, 225],\n",
              "         [125, 183, 225]]], dtype=uint8)\n",
              " orig_shape: (1536, 2040)\n",
              " path: '/content/1.jpg'\n",
              " probs: None\n",
              " save_dir: 'runs/detect/predict'\n",
              " speed: {'preprocess': 5.473550000033356, 'inference': 288.03673699985666, 'postprocess': 1.7355679999582208}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# æ‰“å¼€è§†é¢‘æ–‡ä»¶\n",
        "# video_path = \"path/to/your/video/file.mp4\"\n",
        "import cv2\n",
        "cap = cv2.VideoCapture(0)   # 0è¡¨ç¤ºé»˜è®¤æ‘„åƒå¤´ï¼Œå¦‚æžœæœ‰å¤šä¸ªæ‘„åƒå¤´ï¼Œå¯ä»¥å°è¯•ä½¿ç”¨1, 2, ç­‰\n",
        "\n",
        "# éåŽ†è§†é¢‘å¸§\n",
        "while cap.isOpened():\n",
        "    # ä»Žè§†é¢‘ä¸­è¯»å–ä¸€å¸§\n",
        "    success, frame = cap.read()\n",
        "\n",
        "    if success:\n",
        "        # åœ¨è¯¥å¸§ä¸Šè¿è¡ŒYOLOv8æŽ¨ç†\n",
        "        results = model(frame)\n",
        "\n",
        "        # åœ¨å¸§ä¸Šå¯è§†åŒ–ç»“æžœ\n",
        "        annotated_frame = results[0].plot()\n",
        "\n",
        "        # æ˜¾ç¤ºå¸¦æ³¨é‡Šçš„å¸§\n",
        "        cv2.imshow(\"YOLOv8æŽ¨ç†\", annotated_frame)\n",
        "\n",
        "        # å¦‚æžœæŒ‰ä¸‹'q'åˆ™ä¸­æ–­å¾ªçŽ¯\n",
        "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "            break\n",
        "    else:\n",
        "        # å¦‚æžœè§†é¢‘ç»“æŸåˆ™ä¸­æ–­å¾ªçŽ¯\n",
        "        break\n",
        "\n",
        "# é‡Šæ”¾è§†é¢‘æ•èŽ·å¯¹è±¡å¹¶å…³é—­æ˜¾ç¤ºçª—å£\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "rFgMYuB7I5w4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}